{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiyomi0917/0417pdsnd_github/blob/main/Ono%EF%BC%BFDA_PJ0623.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkE0b0TlkjKI",
        "outputId": "a2717f30-24c5-429e-d2a8-394d394e6975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Janome==0.3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpZsn5fjzKQt",
        "outputId": "9cdf6aae-6063-492b-8f7b-9a5ac8916958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Janome==0.3.7 in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from janome.tokenizer import Tokenizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/drive/MyDrive/dataset_0619.xlsx'\n",
        "xl = pd.ExcelFile(file_path)"
      ],
      "metadata": {
        "id": "Lj4qz_jIk8g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the desired sheet into a DataFrame\n",
        "df1 = xl.parse('0619データ')\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df1)\n"
      ],
      "metadata": {
        "id": "knasNber_-4A"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストを分割する関数_すべての単語を使う\n",
        "t=Tokenizer()\n",
        "def tokenize1(text):\n",
        "    tokens = t.tokenize(text)\n",
        "    noun = []\n",
        "    for token in tokens:\n",
        "        noun.append(token.surface)\n",
        "    return noun\n",
        "\n",
        "# 単語の抽出\n",
        "def tokenize2(text):\n",
        "    tokens = t.tokenize(text)\n",
        "    noun = []\n",
        "    for token in tokens:\n",
        "        # 「名詞」「動詞」「形容詞」「形容動詞」を取り出してください\n",
        "        if token.part_of_speech.split(',')[0] in ['名詞', '動詞', '形容詞', '形容動詞']:\n",
        "            noun.append(token.surface)\n",
        "    return noun\n"
      ],
      "metadata": {
        "id": "99sW_nGX26-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = df1[\"概要\"]\n",
        "labels = df1[\"ハラスメント判定\"].astype(int)  # Convert labels to integer type\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "-gkPej1-0Pub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a0c8dd-8e71-42ba-cb43-38b1242f0a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "108    1\n",
            "109    1\n",
            "110    1\n",
            "111    1\n",
            "112    1\n",
            "Name: ハラスメント判定, Length: 113, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = docs\n",
        "train_labels =labels\n",
        "train_labels = train_labels.astype(int)  # Convert labels to integer type"
      ],
      "metadata": {
        "id": "WJ8bsxXI2oUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#from sklearn.metrics import accuracy_score\n",
        "file_path = '/content/drive/MyDrive/dataset_0619.xlsx'\n",
        "xl = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load a sheet into a DataFrame by name\n",
        "df2 = xl.parse('0620データ')\n",
        "\n",
        "# テストデータの概要とラベルを取得\n",
        "test_data = df2[\"概要\"]\n",
        "test_labels = df2[\"ハラスメント判定\"]\n",
        "\n",
        "# テキストデータをベクトル化するためのVectorizerを定義\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize2)\n",
        "\n",
        "# ベクトル化に使用するトークン化関数（tokenize1）を指定してVectorizerを初期化\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize2)\n",
        "\n",
        "# 学習データをベクトル化\n",
        "train_matrix = vectorizer.fit_transform(train_data)\n",
        "\n",
        "# モデルを設定\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# パラメータでモデルを再学習\n",
        "model.fit(train_matrix, train_labels)\n",
        "\n",
        "# 訓練データの予測\n",
        "train_predictions = model.predict(train_matrix)\n",
        "\n",
        "# 訓練データの正解率を計算して表示\n",
        "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
        "print(\"訓練データの正解率:\", train_accuracy)\n",
        "\n",
        "# テストデータを変換\n",
        "test_matrix = vectorizer.transform(test_data)\n",
        "\n",
        "# テストデータの予測\n",
        "test_predictions = model.predict(test_matrix)\n",
        "\n",
        "# テストデータの正解率を計算して表示\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "print(\"テストデータの正解率:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "2dFH5T3E57-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメーターの値の候補を設定\n",
        "model_param_set_grid = {\"n_estimators\": [50, 100, 200],\n",
        "                        \"max_depth\": [None, 10, 20, 30],\n",
        "                        \"random_state\": [42]}\n",
        "\n",
        "# グリッドサーチでハイパーパラメーターを探索\n",
        "clf = GridSearchCV(model, model_param_set_grid)\n",
        "clf.fit(train_matrix, train_labels)\n",
        "\n",
        "# 最適なパラメータとそのときのスコアを表示\n",
        "print(\"ハイパーパラメーター:{}\".format(clf.best_params_))\n",
        "# print(\"ベストスコア:\", clf.best_score_)\n",
        "\n",
        "# 最適なパラメータでモデルを構築\n",
        "best_model = RandomForestClassifier(**clf.best_params_)\n",
        "\n",
        "# 最適なパラメータでモデルを再学習\n",
        "best_model.fit(train_matrix, train_labels)\n",
        "\n",
        "# 訓練データの予測\n",
        "train_predictions = best_model.predict(train_matrix)\n",
        "\n",
        "# 訓練データの正解率を計算して表示\n",
        "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
        "print(\"訓練データの正解率:\", train_accuracy)\n",
        "\n",
        "# テストデータを変換\n",
        "test_matrix = vectorizer.transform(test_data)\n",
        "\n",
        "# テストデータの予測\n",
        "test_predictions = best_model.predict(test_matrix)\n",
        "\n",
        "# テストデータの正解率を計算して表示\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "print(\"テストデータの正解率:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHQboWDnWo_K",
        "outputId": "1cbce897-a2db-4cdc-826b-43acd34f1388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ハイパーパラメーター:{'max_depth': None, 'n_estimators': 50, 'random_state': 42}\n",
            "訓練データの正解率: 1.0\n",
            "テストデータの正解率: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn import svm\n",
        "import pickle\n",
        "\n",
        "#学習モデルの保存\n",
        "with open('model.pickle', mode='wb') as f:\n",
        "    pickle.dump(best_model,f,protocol=2)\n"
      ],
      "metadata": {
        "id": "wHCC10Sgv40L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}