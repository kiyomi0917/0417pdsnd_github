{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiyomi0917/0417pdsnd_github/blob/main/OK%EF%BC%BFProject623.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkE0b0TlkjKI",
        "outputId": "a2717f30-24c5-429e-d2a8-394d394e6975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Janome==0.3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpZsn5fjzKQt",
        "outputId": "9cdf6aae-6063-492b-8f7b-9a5ac8916958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Janome==0.3.7 in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from janome.tokenizer import Tokenizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/drive/MyDrive/dataset_0619.xlsx'\n",
        "xl = pd.ExcelFile(file_path)"
      ],
      "metadata": {
        "id": "Lj4qz_jIk8g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the desired sheet into a DataFrame\n",
        "df1 = xl.parse('0619データ')\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knasNber_-4A",
        "outputId": "eed7ba0c-828b-492d-f846-b56e173aaf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    概要  \\\n",
            "0    社員Ａの上司Ｂは、小さなミスでも、その場で説明を求め、「仕事は正確に！」と叱る。先日も、報告...   \n",
            "1    社員Ａは、上司Ｂから、出張の回数を制限されたこと、自身がメンタル不調のため、上司Ｂの承認を得...   \n",
            "2    部下は社内の宴会があった翌日、朝の会議に遅刻したら、上司から皆の前で大声で怒鳴られた。\\n部...   \n",
            "3                        会議中に居眠りをしている社員に対して上司が厳しく注意した。   \n",
            "4    職員は普段からマネージャーに無視されていると感じている。ある日、年間自己目標テーマの進め方に...   \n",
            "..                                                 ...   \n",
            "108                          業務品質が改善しない部下の頭を上司が定規で叩いた。   \n",
            "109  部下が職務遂行上、問題行動を取ったことに対し、上司らが「チンピラはいらねんだようちは。雑魚は...   \n",
            "110  役場で勤務する職員に対し、上司が複数回にわたり指示をしたが、従わなかったため注意したところ、...   \n",
            "111  上司が女性社員（部下）の不妊治療等の機微な個人情報について、当該社員の了解を得ずに他の社員に...   \n",
            "112  有給休暇取得を申請したところ、上司が当該有給申請により評価が下がるなどと発言して有給休暇取得...   \n",
            "\n",
            "                                                    背景 ハラスメント判定  \n",
            "0    上司Ｂは仕事熱心である。\\n社員Ａはミスが多いので、ミスの無いように細かいことでも注意をしている。        0  \n",
            "1    上司Ｂは社員Ａに対し、出張回数の制限については、経費面の観点から出張回数を制限して欲しいこと...        0  \n",
            "2    社員Ａは日ごろから遅刻が多く、上司Ｂから注意を受けていた。この日は社員Ａの報告が必要な会議で...        0  \n",
            "3                                                  NaN        0  \n",
            "4    課長Ｂは、年間自己目標テーマについては、期初に話し合いを行いながら、テーマを選定している。社...        0  \n",
            "..                                                 ...      ...  \n",
            "108                                                NaN        1  \n",
            "109                                                NaN        1  \n",
            "110                                                NaN        1  \n",
            "111                                                NaN        1  \n",
            "112                                                NaN        1  \n",
            "\n",
            "[113 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストを分割する関数_すべての単語を使う\n",
        "t=Tokenizer()\n",
        "def tokenize1(text):\n",
        "    tokens = t.tokenize(text)\n",
        "    noun = []\n",
        "    for token in tokens:\n",
        "        noun.append(token.surface)\n",
        "    return noun\n",
        "\n",
        "# 単語の抽出\n",
        "def tokenize2(text):\n",
        "    tokens = t.tokenize(text)\n",
        "    noun = []\n",
        "    for token in tokens:\n",
        "        # 「名詞」「動詞」「形容詞」「形容動詞」を取り出してください\n",
        "        if token.part_of_speech.split(',')[0] in ['名詞', '動詞', '形容詞', '形容動詞']:\n",
        "            noun.append(token.surface)\n",
        "    return noun\n"
      ],
      "metadata": {
        "id": "99sW_nGX26-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = df1[\"概要\"]\n",
        "labels = df1[\"ハラスメント判定\"].astype(int)  # Convert labels to integer type\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "-gkPej1-0Pub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a0c8dd-8e71-42ba-cb43-38b1242f0a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "108    1\n",
            "109    1\n",
            "110    1\n",
            "111    1\n",
            "112    1\n",
            "Name: ハラスメント判定, Length: 113, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = docs\n",
        "train_labels =labels\n",
        "train_labels = train_labels.astype(int)  # Convert labels to integer type"
      ],
      "metadata": {
        "id": "WJ8bsxXI2oUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#from sklearn.metrics import accuracy_score\n",
        "file_path = '/content/drive/MyDrive/dataset_0619.xlsx'\n",
        "xl = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load a sheet into a DataFrame by name\n",
        "df2 = xl.parse('0620データ')\n",
        "\n",
        "# テストデータの概要とラベルを取得\n",
        "test_data = df2[\"概要\"]\n",
        "test_labels = df2[\"ハラスメント判定\"]\n",
        "\n",
        "# テキストデータをベクトル化するためのVectorizerを定義\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize2)\n",
        "\n",
        "# ベクトル化に使用するトークン化関数（tokenize1）を指定してVectorizerを初期化\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize2)\n",
        "\n",
        "# 学習データをベクトル化\n",
        "train_matrix = vectorizer.fit_transform(train_data)\n",
        "\n",
        "# モデルを設定\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# パラメータでモデルを再学習\n",
        "model.fit(train_matrix, train_labels)\n",
        "\n",
        "# 訓練データの予測\n",
        "train_predictions = model.predict(train_matrix)\n",
        "\n",
        "# 訓練データの正解率を計算して表示\n",
        "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
        "print(\"訓練データの正解率:\", train_accuracy)\n",
        "\n",
        "# テストデータを変換\n",
        "test_matrix = vectorizer.transform(test_data)\n",
        "\n",
        "# テストデータの予測\n",
        "test_predictions = model.predict(test_matrix)\n",
        "\n",
        "# テストデータの正解率を計算して表示\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "print(\"テストデータの正解率:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dFH5T3E57-8",
        "outputId": "bef4cf4a-fae2-4350-f17c-67ee41c61ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データの正解率: 1.0\n",
            "テストデータの正解率: 0.7272727272727273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメーターの値の候補を設定\n",
        "model_param_set_grid = {\"n_estimators\": [50, 100, 200],\n",
        "                        \"max_depth\": [None, 10, 20, 30],\n",
        "                        \"random_state\": [42]}\n",
        "\n",
        "# グリッドサーチでハイパーパラメーターを探索\n",
        "clf = GridSearchCV(model, model_param_set_grid)\n",
        "clf.fit(train_matrix, train_labels)\n",
        "\n",
        "# 最適なパラメータとそのときのスコアを表示\n",
        "print(\"ハイパーパラメーター:{}\".format(clf.best_params_))\n",
        "# print(\"ベストスコア:\", clf.best_score_)\n",
        "\n",
        "# 最適なパラメータでモデルを構築\n",
        "best_model = RandomForestClassifier(**clf.best_params_)\n",
        "\n",
        "# 最適なパラメータでモデルを再学習\n",
        "best_model.fit(train_matrix, train_labels)\n",
        "\n",
        "# 訓練データの予測\n",
        "train_predictions = best_model.predict(train_matrix)\n",
        "\n",
        "# 訓練データの正解率を計算して表示\n",
        "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
        "print(\"訓練データの正解率:\", train_accuracy)\n",
        "\n",
        "# テストデータを変換\n",
        "test_matrix = vectorizer.transform(test_data)\n",
        "\n",
        "# テストデータの予測\n",
        "test_predictions = best_model.predict(test_matrix)\n",
        "\n",
        "# テストデータの正解率を計算して表示\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "print(\"テストデータの正解率:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHQboWDnWo_K",
        "outputId": "1cbce897-a2db-4cdc-826b-43acd34f1388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ハイパーパラメーター:{'max_depth': None, 'n_estimators': 50, 'random_state': 42}\n",
            "訓練データの正解率: 1.0\n",
            "テストデータの正解率: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn import svm\n",
        "import pickle\n",
        "\n",
        "#学習モデルの保存\n",
        "with open('model.pickle', mode='wb') as f:\n",
        "    pickle.dump(best_model,f,protocol=2)\n"
      ],
      "metadata": {
        "id": "wHCC10Sgv40L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}